{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.constant(10, dtype=tf.float32)\n",
    "node2 = tf.constant(20, dtype=tf.float32)\n",
    "\n",
    "node3 = node1 + node2\n",
    "\n",
    "# 그래프를 실행시키기 위해서는 session이라는게 필요해요(runner)\n",
    "sess = tf.Session()  # 2.x버전에서는 session이 삭제되었어요!\n",
    "\n",
    "print(sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "# Data Flow Graph에 입력값을 주려면 어떻게 해야 하나요?\n",
    "# placeholder를 이용해요!\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.placeholder(dtype=tf.float32)\n",
    "node2 = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "node3 = node1 + node2\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "result = sess.run(node3, feed_dict={node1 : 10,\n",
    "                                    node2 : 20})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : [[-0.6718051]], b : [-0.13792363], loss : 102.87015533447266\n",
      "W : [[2.0371153]], b : [0.866004], loss : 0.0032703527249395847\n",
      "W : [[2.0134661]], b : [0.951395], loss : 0.00043031160021200776\n",
      "W : [[2.0048919]], b : [0.9823527], loss : 5.672912811860442e-05\n",
      "W : [[2.0017762]], b : [0.99358636], loss : 7.492568784073228e-06\n",
      "W : [[2.0006516]], b : [0.99764943], loss : 1.006370212053298e-06\n",
      "W : [[2.0002372]], b : [0.9991496], loss : 1.3190128811402246e-07\n",
      "W : [[2.0000985]], b : [0.9996586], loss : 2.151323386101467e-08\n",
      "W : [[2.000052]], b : [0.9998292], loss : 5.604397390612803e-09\n",
      "W : [[2.000052]], b : [0.9998292], loss : 5.604397390612803e-09\n",
      "예측값은 : [[19.000296]]\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow를 이용해서 Simple Linear Regression을 구현\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set\n",
    "x_data = (np.array([1,2,3,4,5])).reshape(5,1)   # 공부시간 \n",
    "t_data = (np.array([3,5,7,9,11])).reshape(5,1)  # 시험성적\n",
    "  \n",
    "# 2. placeholder   \n",
    "X = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# 3. Weight & bias   \n",
    "W = tf.Variable(tf.random.normal([1,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# 4. Hypothesis or predict model\n",
    "H = tf.matmul(X,W) + b   # y = Wx + b => 2차원행렬로 처리 => y = X dot W + b\n",
    "\n",
    "# 5. W,b를 구하기 위해 평균제곱오차를 이용한 최소제곱법을 통해\n",
    "#    loss function을 정의\n",
    "loss = tf.reduce_mean(tf.square(H - T))\n",
    "\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(loss)\n",
    "\n",
    "# 7. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())   # 초기화 (2.x 넘어오면서 삭제)\n",
    "\n",
    "# 8. 학습을 진행\n",
    "# 반복학습을 진행 ( 1 epoch : training data set 전체를 이용하여 1번 학습하는 것)\n",
    "for step in range(30000):\n",
    "    \n",
    "    _, W_val, b_val, loss_val = sess.run([train,W,b,loss], \n",
    "                                         feed_dict={X : x_data, T : t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('W : {}, b : {}, loss : {}'.format(W_val, b_val, loss_val))\n",
    "        \n",
    "# 9. 학습이 종료된 후 최적의 W와 b가 계산되고 이를 이용한 model이 완성\n",
    "#    prediction(예측)\n",
    "result = sess.run(H, feed_dict={X : [[9]]})\n",
    "print('예측값은 : {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : [[0.20905127]], b : [0.62528613]\n",
      "W : [[1.988679]], b : [1.04087241]\n",
      "W : [[1.99589439]], b : [1.01482255]\n",
      "W : [[1.99851108]], b : [1.00537546]\n",
      "W : [[1.99946004]], b : [1.00194943]\n",
      "W : [[1.99980418]], b : [1.00070697]\n",
      "W : [[1.99992899]], b : [1.00025639]\n",
      "W : [[1.99997425]], b : [1.00009298]\n",
      "W : [[1.99999066]], b : [1.00003372]\n",
      "W : [[1.99999661]], b : [1.00001223]\n"
     ]
    }
   ],
   "source": [
    "# Simple Linear Regression을 python으로 구현해 보아요!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. training data set\n",
    "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "t_data = np.array([3,5,7,9,11]).reshape(5,1)\n",
    "\n",
    "# 2. Weight & bias\n",
    "W = np.random.rand(1,1)   \n",
    "b = np.random.rand(1)\n",
    "\n",
    "# 3. Hypothesis\n",
    "def predict(x):\n",
    "    \n",
    "    y = np.dot(x,W) + b   \n",
    "    \n",
    "    return y\n",
    "\n",
    "# 4. loss_function\n",
    "def loss_func(input_obj):\n",
    "    # input_obj : [W, b]\n",
    "    \n",
    "    input_W = input_obj[0]\n",
    "    input_b = input_obj[1]\n",
    "    \n",
    "    y = np.dot(x_data,input_W) + input_b\n",
    "    \n",
    "    return np.mean(np.power((t_data - y),2))\n",
    "\n",
    "# 5. 편미분을 위한 함수\n",
    "def numerical_derivative(f,x):\n",
    "    \n",
    "    # f : 미분하려고 하는 다변수 함수\n",
    "    # x : 모든 값을 포함하는 numpy array  ex) f'(1.0, 2.0) = (8.0, 15.0)\n",
    "    #     [W, b] \n",
    "    delta_x = 1e-4\n",
    "    derivative_x = np.zeros_like(x)    # [0 0]\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        \n",
    "        idx = it.multi_index   # 현재의 iterator의 index를 추출 => tuple형태로 나와요\n",
    "#         print('현재의 idx : {}'.format(idx))        \n",
    "        \n",
    "        tmp = x[idx]     # 현재 index의 값을 잠시 보존.\n",
    "                         # delta_x를 이용한 값으로 ndarray를 수정한 후 편미분을 계산\n",
    "                         # 함수값을 계산한 후 원상복구를 해 줘야 다음 독립변수에\n",
    "                         # 대한 편미분을 정상적으로 수행할 수 있어요!\n",
    "#         print('현재 temp : {}'.format(tmp))   \n",
    "        x[idx] = tmp + delta_x        \n",
    "        fx_plus_delta = f(x)    # f([1.00001, 2.0])   => f(x + delta_x)\n",
    "        \n",
    "\n",
    "        x[idx] = tmp - delta_x\n",
    "        fx_minus_delta = f(x)    # f([0.99999, 2.0])   => f(x - delta_x)\n",
    "        \n",
    "        derivative_x[idx] = (fx_plus_delta - fx_minus_delta) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp\n",
    "        \n",
    "        it.iternext()\n",
    "        \n",
    "    return derivative_x\n",
    "\n",
    "# learning rate 설정\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# 학습을 진행\n",
    "for step in range(300000):\n",
    "    input_param = np.concatenate((W.ravel(), b.ravel()), axis=0)  # [W b]\n",
    "    derivative_result = learning_rate * numerical_derivative(loss_func,input_param)\n",
    "    \n",
    "    W = W - derivative_result[:1].reshape(1,1)  # W 갱신\n",
    "    b = b - derivative_result[1:]               # b 갱신\n",
    "\n",
    "    if step % 30000 == 0:\n",
    "        print('W : {}, b : {}'.format(W,b))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn을 이용해 구현해보아요 => 정답확인용\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# 1. training data set\n",
    "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "t_data = np.array([3,5,7,9,11]).reshape(5,1)\n",
    "\n",
    "# 2. linear regression model을 생성\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# 3. 학습진행\n",
    "model.fit(x_data,t_data)\n",
    "\n",
    "# 4. loss_function\n",
    "print('W : {}, b : {}'.format(model.coef_,model.intercept_))\n",
    "    \n",
    "#5. predict\n",
    "print(model.predict(([9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세가지 방법으로 구현\n",
    "# python은 정확도 떨어짐\n",
    "# sklearn은 딥러닝에서 구현 불가\n",
    "# => 주로 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
